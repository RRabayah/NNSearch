{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxilliary Helper Functions\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "#flattens a 2d-array\n",
    "def get_flat_list(list1):\n",
    "    unique_elements = []\n",
    "    for x in list1:\n",
    "        unique_elements.append(x.split(','))\n",
    "    unique_elements = flatten(unique_elements)\n",
    "    for x in range(len(unique_elements)):\n",
    "        unique_elements[x] = unique_elements[x].strip()\n",
    "    return unique_elements\n",
    "\n",
    "#tranforms a string of comma-separated values into a list\n",
    "def transform_into_list(list1):\n",
    "    unique_elements = list1.split(',')\n",
    "    for x in range(len(unique_elements)):\n",
    "        unique_elements[x] = unique_elements[x].strip()\n",
    "    return unique_elements\n",
    "\n",
    "#basic range-scaling to get values between 0-1\n",
    "def range_scaling(df_col):\n",
    "    max_col_val = df_col.max()\n",
    "    min_col_val = df_col.min()\n",
    "\n",
    "    df_col = df_col.apply(lambda x: ((x-min_col_val)/(max_col_val-min_col_val)))\n",
    "    return df_col\n",
    "\n",
    "#simple one_hot_encoding, works on lists and strings\n",
    "def one_hot_encode(df1, column):\n",
    "    #Slight generalization - works only on lists and strings -- there is probably a better prebuilt method of doing this.\n",
    "    all_material_occurences = df1[column].tolist()\n",
    "    flat_unique_list = []\n",
    "\n",
    "    #Remove duplicates, check if datatype of argument is a list or not\n",
    "    if(isinstance(all_material_occurences[0],list)):\n",
    "        flat_unique_list = list(set(flatten(all_material_occurences)))\n",
    "    else:\n",
    "        flat_unique_list = list(set(all_material_occurences))\n",
    "    \n",
    "    #Create new column for each item in the list - implement categorical variables\n",
    "    for col in flat_unique_list:\n",
    "        df1[col] = 0\n",
    "\n",
    "    #Convert Material Groups into a binary 0-1 classifier (either 0 or 1)\n",
    "    #TODO: The way I did this is probably wrong - Look into vectorization or list comp. or something\n",
    "    for index, row in df1.iterrows():\n",
    "        list_check = row[column]\n",
    "        if(isinstance(list_check, list)):\n",
    "            for x in list_check:\n",
    "                df1.at[index, x] = 1\n",
    "        else:\n",
    "            df1.at[index, list_check] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df1):\n",
    "    #Get all possible material groups as one long list\n",
    "    all_occurances = df1['MATERIAL GROUP'].tolist()\n",
    "\n",
    "    #Transform str of elements into a list for each row\n",
    "    df1['MATERIAL GROUP'] = df1['MATERIAL GROUP'].apply(lambda x: transform_into_list(x))\n",
    "\n",
    "    #Remove rare items from all the lists in each row, reduces data dimensionality\n",
    "    key_count_dict = Counter(get_flat_list(all_occurances))\n",
    "    elements_to_remove = [k for k, v in key_count_dict.items() if v < 2]\n",
    "    df1['MATERIAL GROUP'] = df1['MATERIAL GROUP'].apply(lambda x: list(set(x) - set(elements_to_remove)))\n",
    "\n",
    "    #Scale numeric values to be 0-1\n",
    "    df1['NO. OF EMPLOYEES'] = range_scaling(df1['NO. OF EMPLOYEES'])\n",
    "    df1['NO. OF SERVICED FACILITIES'] = range_scaling(df1['NO. OF SERVICED FACILTIIES'])\n",
    "\n",
    "    #Encode categorical variables\n",
    "    one_hot_encode(df1, 'MATERIAL GROUP')\n",
    "    one_hot_encode(df1, 'SECTOR')\n",
    "\n",
    "    #Drop unneeded columns\n",
    "    useless_columns = ['PICK UP', 'MATERIAL GROUP', 'SECTOR', 'NO. OF SERVICED FACILTIIES']\n",
    "    for x in useless_columns:\n",
    "        df1.drop([x], axis = 1, inplace = True)\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_in_dataset(path1, path2, path3):\n",
    "    df1 = pd.read_csv(path1)\n",
    "    df2 = pd.read_csv(path2)\n",
    "    df3 = pd.read_csv(path3)\n",
    "    return df1, df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(df1):\n",
    "\n",
    "    distances = pd.DataFrame()\n",
    "    distances['from'] = \"\"\n",
    "    distances['to'] = \"\"\n",
    "    distances['distance'] = \"\"\n",
    "\n",
    "    for index1, row1 in df1.iterrows():\n",
    "        dataframe_excluded = df1.drop(index1, axis = 0)\n",
    "        row1_features = row1.drop(labels=['FACILITY NAME'])\n",
    "        row1_name = row1['FACILITY NAME']\n",
    "        row1f_list = row1_features.tolist()\n",
    "        \n",
    "        for index2, row2 in dataframe_excluded.iterrows():\n",
    "            row2_name = row2['FACILITY NAME']\n",
    "            row2_features = row2.drop(labels = ['FACILITY NAME'])\n",
    "            row2f_list = row2_features.tolist()\n",
    "\n",
    "            distance = math.dist(row1f_list, row2f_list)\n",
    "            distances.loc[len(distances.index)] = [row1_name, row2_name, distance] \n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline to generate all the distances\n",
    "def complete_pipeline():\n",
    "    b2b_clients_df, facility_managers_df, collections_df = load_in_dataset('./Data/List B2B(1) - Sheet1.csv',\n",
    "                                            './Data/FacilityManagers (2) - Worksheet.csv',\n",
    "                                            './Data/Company Collections & Waste Generation metrics - Sheet1.csv')\n",
    "    clean_data = process_data(b2b_clients_df)\n",
    "    similarities = find_similar(clean_data)\n",
    "    similarities.to_csv('distances.csv')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_most_similar(business, n):\n",
    "    business_dist_df = pd.read_csv('./distances.csv')\n",
    "    business_dist_df.loc[business_dist_df['from'] == business]\n",
    "    sorted_business = business_dist_df.sort_values('distance',ascending = True).groupby('from').head(n)\n",
    "    print(sorted_business.loc[sorted_business['from'] == business])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete processing pipeline\n",
    "complete_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0         from             to  distance\n",
      "91          91  Mc Donald's      Nespresso  1.414270\n",
      "92          92  Mc Donald's           STOP  1.732277\n",
      "79          79  Mc Donald's        IT CAFE  2.000026\n",
      "94          94  Mc Donald's  Intersalonica  2.000196\n",
      "78          78  Mc Donald's  Interamerican  2.000316\n"
     ]
    }
   ],
   "source": [
    "find_n_most_similar(\"Mc Donald's\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
